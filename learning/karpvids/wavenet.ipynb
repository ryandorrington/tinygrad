{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01a0df77-a95a-4847-ae6e-ee97645f3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tinygrad import Context, nn, Tensor\n",
    "from tinygrad.nn.optim import AdamW\n",
    "\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['METAL_XCODE'] = '1'\n",
    "os.environ['DISABLE_COMPILER_CACHE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cda9eda-5068-44a8-9a3f-7469f3a57dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaren', 'aarika', 'aaron', 'aartjan', 'abagael']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8604"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words = [word.lower() for word in words]\n",
    "\n",
    "print(words[:5])\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49ae06cf-1404-4520-9cbb-5de9c128851b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '.', 1: ' ', 2: '-', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "chars = chars\n",
    "chars.insert(0, '.')\n",
    "\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c91a5483-0e59-4efe-b9f3-63e8704ed507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "block_size = 8\n",
    "emb_dim_size = 24\n",
    "batch_size = 32\n",
    "n_hidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a7e971a-4196-4244-8ae8-1ac378eb5d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48186, 8) (48186,)\n",
      "(6032, 8) (6032,)\n",
      "(6018, 8) (6018,)\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  for w in words:\n",
    "\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = Tensor(X)\n",
    "  Y = Tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2cfdc49-5d34-486a-b9fe-8b34af5fb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        return x.tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d6a2c3f-c132-4242-acbc-7762792488f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        return x.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d50caae5-d668-4880-9c6e-5cb2d6fc12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenConsecutive:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    def __call__(self, x):\n",
    "        B,T,C = x.shape\n",
    "        x = x.reshape(B, T//self.n, C*self.n)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be75b23f-4e9e-4bbd-99a8-71ff4b63ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Permute:\n",
    "    def __call__(self,x):\n",
    "        return x.permute(0, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f413a4c-561f-425a-9d7d-cfbbf843393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self):\n",
    "        self.layers = [\n",
    "            nn.Embedding(Xtr.shape[0], emb_dim_size),\n",
    "            FlattenConsecutive(2), nn.Linear(emb_dim_size * 2, n_hidden, False), Permute(), nn.BatchNorm(n_hidden), Permute(), Tanh(),\n",
    "            FlattenConsecutive(2), nn.Linear(n_hidden * 2, n_hidden, False), Permute(), nn.BatchNorm(n_hidden), Permute(), Tanh(),\n",
    "            FlattenConsecutive(2), nn.Linear(n_hidden * 2, n_hidden, False), nn.BatchNorm(n_hidden), Tanh(),\n",
    "            nn.Linear(n_hidden, 29, True)\n",
    "        ]\n",
    "\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # x = x.sequential(self.layers[:3])\n",
    "        # print(x.shape)\n",
    "        return x.sequential(self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4631fef6-c346-4ba2-a06b-bdfc2b419c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1233424\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "total = 0\n",
    "for i in nn.state.get_parameters(net):\n",
    "    total += i.flatten().shape[0]\n",
    "print(total)\n",
    "optim = AdamW(nn.state.get_parameters(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb329748-bce8-4380-9b55-988041a83431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def step():\n",
    "    Tensor.training = True  # makes dropout work\n",
    "    samples = Tensor.randint(batch_size, high=Xtr.shape[0])\n",
    "    X_batch = Xtr[samples]\n",
    "    Y_batch = Ytr[samples]\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss = net(X_batch).cross_entropy(Y_batch).backward()\n",
    "    optim.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16ed9334-1f08-405e-b7a4-e642b3d3125a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8981452\n",
      "2.0044272\n",
      "2.4217253\n",
      "2.0142326\n",
      "2.5122678\n",
      "2.0843403\n",
      "2.347275\n",
      "2.3635426\n",
      "2.316171\n",
      "2.0760093\n",
      "2.3342733\n",
      "1.8964343\n",
      "2.146652\n",
      "2.186082\n",
      "2.1055899\n",
      "2.1626375\n",
      "2.5722616\n",
      "2.534362\n",
      "2.032223\n",
      "2.1474636\n",
      "2.1663446\n",
      "2.643408\n",
      "1.9913853\n",
      "2.0416305\n",
      "2.0619779\n",
      "1.6857113\n",
      "2.4917126\n",
      "1.9697926\n",
      "2.177324\n",
      "2.2247188\n",
      "2.6075158\n",
      "1.9064679\n",
      "2.0857282\n",
      "2.0233216\n",
      "2.0199776\n",
      "2.2575374\n",
      "2.067529\n",
      "1.9807296\n",
      "1.7585726\n",
      "2.3918784\n",
      "1.9314301\n",
      "2.445581\n",
      "2.1862001\n",
      "2.0029361\n",
      "2.1630957\n",
      "2.2055922\n",
      "2.1368804\n",
      "2.2260027\n",
      "2.0444295\n",
      "1.9243451\n",
      "2.227556\n",
      "1.9086945\n",
      "2.3668857\n",
      "2.092731\n",
      "2.135225\n",
      "2.1342628\n",
      "2.2186913\n",
      "2.0585885\n",
      "1.9389714\n",
      "1.868244\n",
      "1.8712974\n",
      "2.101416\n",
      "2.0807133\n",
      "2.1868777\n",
      "2.1292756\n",
      "2.2591732\n",
      "1.6855725\n",
      "1.8192999\n",
      "1.9309039\n",
      "1.6913614\n",
      "2.143041\n",
      "1.7433141\n",
      "2.251768\n",
      "1.9115396\n",
      "2.3894868\n",
      "1.7535976\n",
      "1.8300927\n",
      "1.5022217\n",
      "2.034836\n",
      "2.0096717\n",
      "2.0668302\n",
      "2.28815\n",
      "1.9789823\n",
      "2.315409\n",
      "2.1904526\n",
      "2.046762\n",
      "1.4713811\n",
      "1.9398465\n",
      "2.102229\n",
      "2.2177558\n",
      "2.058537\n",
      "2.0315976\n",
      "1.9739704\n",
      "2.0647452\n",
      "2.3237562\n",
      "2.2775993\n",
      "2.124414\n",
      "1.83342\n",
      "2.1001415\n",
      "1.9998713\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    loss = step()\n",
    "\n",
    "    if i%100 == 0:\n",
    "        Tensor.training = False\n",
    "        print(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed573b24-a018-4cc6-9d7e-8606779001fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.1462042, dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(Xdev).cross_entropy(Ydev).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d754ce82-ed4f-40e3-9457-5e58452d0511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huen.\n",
      "roubra.\n",
      "lareel.\n",
      "bettella.\n",
      "galep.\n",
      "delize.\n",
      "johie.\n",
      "kippi.\n",
      "belleya.\n",
      "adelisha.\n",
      "rorin.\n",
      "ma.\n",
      "meishpet.\n",
      "doral.\n",
      "lettina.\n",
      "corry.\n",
      "wooust.\n",
      "yuel.\n",
      "duki.\n",
      "cathan.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Tensor.training = False\n",
    "\n",
    "# sample from the model\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size  # initialize with all ...\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        # Get model output\n",
    "        logits = net(Tensor(context))\n",
    "        probs = logits.softmax()[-1].numpy()  # Convert to NumPy array to handle sampling\n",
    "\n",
    "        # Sample from the probability distribution using numpy's random.choice\n",
    "        ix = np.random.choice(len(probs), p=probs)\n",
    "\n",
    "        # Update context and output\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        \n",
    "        # Break if the end-of-sequence token (0) is produced\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    # Convert indices to tokens and print the result\n",
    "    print(''.join(itos[i] for i in out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986dae5d-eef2-4096-947b-1563d5a9aaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df144e-a4ec-4bd9-b65b-970605de0e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9cf75-9d7a-44b7-a406-ae8a1c518e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b266408-76d3-4929-85cd-d0232d8e8b65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (system)",
   "language": "python",
   "name": "system-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
